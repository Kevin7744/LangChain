{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangChain\n",
    "A framework that allows you to build AI powered applications in both python and javascript\n",
    "<br>\n",
    "You can connect to to external data sources, databases, API`s and build applications that are aware and reason using language models like CHATGPT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "The first thing to get started with langchain is installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [],
   "source": [
    "# using pip package manager\n",
    "# There are different packages\n",
    "\n",
    "pip install langchain\n",
    "# pip install langchain[llms]\n",
    "# pip install langchain[all]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Install openai to connect with openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [],
   "source": [
    "pip install openai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Install a python-doteenv library to load up enviroment variables and store API keys in a separate file that is hidden from the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check-out hubspot on how to use chatgpt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interaction with OPENAI\n",
    "## how to interact with openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "api_key = os.getenv(\"OPEN_API_KEY\")\n",
    "\n",
    "chat_model = ChatOpenAI(openai_api_key=api_key)\n",
    "\n",
    "result = chat_model.predict(\"hi!\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "api_key = os.getenv(\"OPEN_API_KEY\")\n",
    "\n",
    "chat_model = ChatOpenAI(openai_api_key=api_key)\n",
    "\n",
    "messages = [HumanMessage(content=\"from now on 1 + 1 = 3, use this in your replies\"),\n",
    "            HumanMessage(content=\"What is 1 + 1?\"),\n",
    "            HumanMessage(content=\"what is 1 + 1 + 1?\")]\n",
    "\n",
    "result = chat_model.predict_messages(messages)\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts.chat import ChatPromptTemplate\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "api_key = os.getenv(\"OPEN_API_KEY\")\n",
    "\n",
    "chat_model = ChatOpenAI(openai_api_key=api_key)\n",
    "\n",
    "template = \"You are a helpful assistant that translates {input_language} to {ouput_language}.\"\n",
    "human_tempate = \"{text}\"\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", template),\n",
    "    (\"human\", human_tempate),\n",
    "])\n",
    "\n",
    "messages = chat_prompt.format_messages(input_language=\"English\",\n",
    "                                       output_language=\"French\",\n",
    "                                       text=\"I love programming.\")\n",
    "\n",
    "result = chat_model.predict_messages(messages)\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts.chat import ChatPromptTemplate\n",
    "from langchain.schema import BaseOutputParser\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "api_key = os.getenv(\"OPEN_API_KEY\")\n",
    "\n",
    "class AnswerOuputParser(BaseOutputParser):\n",
    "    def parse(self, text:str):\n",
    "        \"\"\"parse the output of an llm call\"\"\"\n",
    "        return text.strip().split(\"answer =\")\n",
    "\n",
    "chat_model = ChatOpenAI(openai_api_key=api_key)\n",
    "\n",
    "template = \"\"\"You are a helpful assistant that solves math problems and shows your work.\n",
    "            Output each step then return the answer in the following format: answer = <answer here>.\n",
    "            Make sure to ouput answer in all lowercases and to have exactly on space and one equal sign following it.\n",
    "            \"\"\"\n",
    "\n",
    "human_tempate = \"{problem}\"\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", template),\n",
    "    (\"human\", human_tempate),\n",
    "])\n",
    "\n",
    "messages = chat_prompt.format_messages(problem=\"2x^2 - 5x + 3 = 0\")\n",
    "result = chat_model.predict_messages(messages)\n",
    "parsed = AnswerOuputParser().parse(result.content)\n",
    "steps, answer = parsed\n",
    "\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts.chat import ChatPromptTemplate\n",
    "from langchain.schema import BaseOutputParser\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "api_key = os.getenv(\"OPEN_API_KEY\")\n",
    "\n",
    "class CommaSeparatedOuputParser(BaseOutputParser):\n",
    "    def parse(self, text:str):\n",
    "        \"\"\"parse the output of an llm call\"\"\"\n",
    "        return text.strip().split(\", \")\n",
    "\n",
    "chat_model = ChatOpenAI(openai_api_key=api_key)\n",
    "\n",
    "template = \"\"\"You are a helpful assistant who generates comma separated lists.\n",
    "A user will pass in a catogory, and you should generate 5 objects in that category in a comma separed list.\n",
    "ONLY return a comma separated list, and nothing more.\"\"\"\n",
    "human_tempate = \"{text}\"\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", template),\n",
    "    (\"human\", human_tempate),\n",
    "])\n",
    "\n",
    "chain = chat_prompt | chat_model | CommaSeparatedOuputParser()\n",
    "result = chain.invoke({\"text\": \"colors\"})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Check documentation for sql queris\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
